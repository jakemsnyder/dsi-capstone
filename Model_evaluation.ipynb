{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "generic = pd.read_csv(\"Data/generic_mrp_results.csv\")\n",
    "specific = pd.read_csv(\"Data/specific_mrp_results.csv\")\n",
    "result = pd.read_csv(\"Data/2018_results.csv\", encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = generic[generic.Demographic_Type == 'District']\n",
    "specific = specific[specific.Demographic_Type == 'District']\n",
    "\n",
    "generic = generic.dropna()\n",
    "specific = specific.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((428, 3), (428, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic.shape, specific.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(generic.Demographic == specific.Demographic)== 428"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the results only with avaiable district \n",
    "\n",
    "result = result[result.Dist.isin(generic.Demographic)]\n",
    "result = result[['REP.', 'Dist']]\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickup available results \n",
    "\n",
    "result = result[result['REP.'] != 'â€”']\n",
    "result = result[result['REP.'] != 'Unc.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to float\n",
    "\n",
    "result['REP.'] = result['REP.'].str.rstrip('%').astype('float')/100\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = generic[generic.Demographic.isin(result.Dist)]\n",
    "specific = specific[specific.Demographic.isin(result.Dist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = specific.sort_values(by = ['Demographic'])\n",
    "generic = generic.sort_values(by = ['Demographic'])\n",
    "result = result.sort_values(by = ['Dist'])\n",
    "specific = specific.reset_index()\n",
    "generic = generic.reset_index()\n",
    "result = result.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_g = generic.Vote_R\n",
    "y_s = specific.Vote_R\n",
    "y_r = result['REP.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean square error\n",
    "import numpy as np\n",
    "mse_g = np.mean((y_g - y_r)**2)\n",
    "mse_s = np.mean((y_s - y_r)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005918537234662504, 0.0047357923785882345)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_g, mse_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, in terms of whether republican is a majority \n",
    "y_g_acc = np.where(y_g > 0.5, 1,0)\n",
    "y_s_acc = np.where(y_s > 0.5, 1,0)\n",
    "y_r_acc = np.where(y_r > 0.5, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_g = sum(y_g_acc == y_r_acc)/len(y_g)\n",
    "accuracy_s = sum(y_s_acc == y_r_acc)/len(y_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8582474226804123, 0.8788659793814433)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_g, accuracy_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison = {'Model':['generic', 'specific'],\n",
    "              'Accuracy':[accuracy_g, accuracy_s],\n",
    "              'MSE':[mse_g, mse_s]}\n",
    "\n",
    "df = pd.DataFrame(Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generic</td>\n",
       "      <td>0.858247</td>\n",
       "      <td>0.005919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>specific</td>\n",
       "      <td>0.878866</td>\n",
       "      <td>0.004736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       MSE\n",
       "0   generic  0.858247  0.005919\n",
       "1  specific  0.878866  0.004736"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Model_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
